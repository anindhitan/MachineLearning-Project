# -*- coding: utf-8 -*-
"""Image Classification Model Deployment Anin.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15k5aQw3lTQtP_XMaF1RCMGlx_SvLG2aI

# Nama : Anindhita Nisitasari

# Set The Data
"""

!pip install scikit-image==0.16.2
!pip install tensorflow==1.15
!pip install keras==2.2.4
!pip install h5py==2.10.0
!pip install opencv-python
!pip install imgaug
!pip install IPython[all]

# install package
!pip install -q kaggle
from google.colab import files
import io
import zipfile
import sklearn
from sklearn import datasets
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dense, Flatten
from tensorflow.keras.layers import Dropout
from tensorflow.keras.optimizers import Adam

! chmod 600 /content/kaggle.json

! KAGGLE_CONFIG_DIR=/content/ kaggle datasets download -d mahmoudreda55/satellite-image-classification

import zipfile,os,shutil
local_zip = '/content/satellite-image-classification.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

base_dir = '/tmp/data'
cloudy_dir = os.path.join(base_dir,'cloudy')
desert_dir = os.path.join(base_dir, 'desert')
green_dir = os.path.join(base_dir, 'green_area')
water_dir = os.path.join(base_dir, 'water')

cloudy_total = len(os.listdir(cloudy_dir))
desert_total = len(os.listdir(desert_dir))
green_total = len(os.listdir(green_dir))
water_total = len(os.listdir(water_dir))

# to know the amount of the data
print("Cloudy total image      : ",cloudy_total)
print("Desert total image      : ",desert_total)
print("Green Area total image  : ",green_total)
print("Water total image       : ",water_total)

val_size = 0.2

Train_datagen = ImageDataGenerator(
    rotation_range = 45,
    brightness_range = [0.2,1.0],
    shear_range = 0.2,
    zoom_range = 0.2,
    horizontal_flip = True,
    fill_mode = "nearest",
    rescale = 1./255,
    validation_split = val_size
)

Validation_datagen = ImageDataGenerator(
    rotation_range = 45,
    brightness_range = [0.2,1.0],
    shear_range = 0.2,
    zoom_range = 0.2,
    horizontal_flip = True,
    fill_mode = "nearest",
    rescale = 1./255,
    validation_split = val_size
)

# Train dan Validation generator  dengan mode categorical
Train_generator = Train_datagen.flow_from_directory(
    base_dir,
    target_size = (150,150),
    color_mode = "rgb",
    class_mode = "categorical",
    batch_size = 16,
    shuffle = True,
    subset = "training"
)

Validation_generator = Validation_datagen.flow_from_directory(
    base_dir,
    target_size = (150,150),
    color_mode = "rgb",
    class_mode = "categorical",
    batch_size = 16,
    shuffle = False,
    subset = "validation"
)

"""# Model"""

from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.optimizers import SGD

import keras
import keras.utils
from keras import utils as np_utils
from tensorflow.keras.layers import Input

# Pembuatan Model dengan tipe Sequential
Model = Sequential(
    [
     # Activation menggunakan relu + softmax
     Conv2D(32, (3,3), strides = (1,1), activation = 'relu' , input_shape = (150,150,3)),
     MaxPooling2D(pool_size = (2,2), padding = 'valid'),
     Conv2D(64, (3,3), strides = (1,1), activation = 'relu' ),
     MaxPooling2D(pool_size = (2,2), padding = 'valid'),
     Conv2D(128, (3,3), strides = (1,1), activation = 'relu' ),
     MaxPooling2D(pool_size = (2,2), padding = 'valid'),
     Flatten(),
     # Droupout
     Dropout(0.2),
     Dense(128, activation = 'relu'),
     Dense(4, activation='softmax')
    ]
)

# Penggunaan Optimizer 'Adam' dengan learning rate 0.00146
Adam(learning_rate=0.00146, name='Adam')
Model.compile(optimizer = 'Adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])

def scheduler(epoch, lr):
  if epoch < 5:
    return lr
  else:
    return lr * tf.math.exp(-0.1)

lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)
tb_callback = tf.keras.callbacks.TensorBoard(
    log_dir='logs', histogram_freq=0, write_graph=True, write_images=False,
    update_freq='epoch', embeddings_freq=0,
    embeddings_metadata=None
)

Model.summary()

# Proses Training 
batch_size = 1

with tf.device("/device:GPU:0"):
  history = Model.fit(Train_generator, 
                    epochs =  100, 
                    steps_per_epoch = 50//batch_size, 
                    validation_data = Validation_generator, 
                    verbose = 1, 
                    validation_steps = 50//batch_size,
                    callbacks =[lr_schedule, tb_callback])

"""# Accuracy and Plot"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from keras_preprocessing.image import load_img
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import keras.utils as image
# %matplotlib inline

# Upload File ke google colabs
uploaded = files.upload()

# pengkondisian
for file_upload in uploaded.keys():

  path = file_upload
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  # Membuat numpy vstack array untuk hasil prediksi 
  images = np.vstack([x])
  classes = Model.predict(images, batch_size=16)
  
  print("\n")
  print('Prediction Result : ',classes[0],'\n')

  if classes[0][0] == 1:
    print('Image Category : Cloudy')
  elif classes[0][1] == 1:
    print('Image Category : Desert')
  elif classes[1][1] == 1:
    print('Image Category : Green Area')
  else:
    print('Image Category : Water')

# Mengambil Nilai Accuracy 
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

"""# Save to TF-Lite"""

# Convert Model.
converter = tf.lite.TFLiteConverter.from_keras_model(Model)
tflite_model = converter.convert()

# Save the model.
with open('RPS_model.tflite', 'wb') as f:
  f.write(tflite_model)